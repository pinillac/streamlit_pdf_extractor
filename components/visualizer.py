"""
Results Visualizer Component
Handles all data visualization and charting for the PDF extractor
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from typing import List, Dict, Any, Optional
from collections import Counter
import json

class ResultsVisualizer:
    """Handles visualization of extraction results"""
    
    def __init__(self):
        self.color_scheme = {
            'bomba': '#1f77b4',
            'horno': '#ff7f0e',
            'intercambiador': '#2ca02c',
            'recipiente': '#d62728',
            'compresor': '#9467bd',
            'instrumento': '#8c564b',
            'tuberia': '#e377c2',
            'custom': '#7f7f7f'
        }
        
    def render_charts(self, results: List[Dict[str, Any]]):
        """
        Render main visualization charts
        
        Args:
            results: List of extraction results
        """
        if not results:
            st.warning("No data available for visualization")
            return
        
        # Create DataFrame
        df = pd.DataFrame(results)
        
        # Layout columns
        col1, col2 = st.columns(2)
        
        with col1:
            self.render_tag_distribution_pie(df)
        
        with col2:
            self.render_tag_timeline(df)
        
        # Full width charts
        self.render_document_comparison(df)
        self.render_tag_frequency_chart(df)

    def render_tag_distribution_pie(self, df: pd.DataFrame):
        """
        [VERSIÃ“N ACTUALIZADA]
        Renderiza un grÃ¡fico de tarta de la distribuciÃ³n de tags, ahora basado en la
        columna 'clasificacion_level_2' de la taxonomÃ­a.
        """
        st.subheader("ðŸ“Š DistribuciÃ³n de Tags por CategorÃ­a (Level 2)")
        
        # --- INICIO DE LA MODIFICACIÃ“N ---
        # Cambiamos 'tipo_elemento' por 'clasificacion_level_2'
        target_column = 'clasificacion_level_2'
        
        # ProgramaciÃ³n defensiva: Verificar que la nueva columna exista
        if target_column not in df.columns or df[target_column].empty:
            st.warning(f"No se encontraron datos en la columna '{target_column}' para generar el grÃ¡fico. "
                    "AsegÃºrese de que el procesamiento se completÃ³ y el CSV de taxonomÃ­a estÃ¡ correcto.")
            return

        # Contar por la nueva columna de taxonomÃ­a
        type_counts = df[target_column].value_counts()
        
        # --- FIN DE LA MODIFICACIÃ“N ---

        # La lÃ³gica de creaciÃ³n del grÃ¡fico se mantiene, pero ahora usa los nuevos datos
        fig = go.Figure(data=[go.Pie(
            labels=type_counts.index,
            values=type_counts.values,
            hole=.3,
            # El mapeo de colores sigue funcionando si los nombres de Level 2 coinciden
            marker_colors=[self.color_scheme.get(str(t).lower(), '#7f7f7f') for t in type_counts.index]
        )])
        
        fig.update_layout(
            showlegend=True,
            height=400,
            margin=dict(l=20, r=20, t=40, b=20)
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Actualizar las mÃ©tricas para que reflejen la nueva columna
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total de CategorÃ­as (L2)", len(type_counts))
        with col2:
            st.metric("CategorÃ­a MÃ¡s ComÃºn", type_counts.index[0] if len(type_counts) > 0 else "N/A")
        with col3:
            st.metric("CategorÃ­a Menos ComÃºn", type_counts.index[-1] if len(type_counts) > 0 else "N/A")
        
    def render_tag_timeline(self, df: pd.DataFrame):
        """Render timeline of tags by page number"""
        st.subheader("ðŸ“ˆ Tag Distribution by Page")
        
        # Group by page and count
        page_counts = df.groupby('pagina_encontrada').size().reset_index(name='count')
        
        # Create line chart
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=page_counts['pagina_encontrada'],
            y=page_counts['count'],
            mode='lines+markers',
            name='Tags per Page',
            line=dict(color='#1f77b4', width=2),
            marker=dict(size=8)
        ))
        
        fig.update_layout(
            xaxis_title="Page Number",
            yaxis_title="Number of Tags",
            height=400,
            margin=dict(l=20, r=20, t=40, b=20),
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, use_container_width=True)
  

    def render_document_comparison(self, df: pd.DataFrame):
        """
        [VERSIÃ“N ACTUALIZADA]
        Renderiza una comparaciÃ³n entre documentos, agrupando por 'clasificacion_level_2'.
        """
        st.subheader("ðŸ“‘ ComparaciÃ³n de Tags por Documento")

        # --- INICIO DE LA MODIFICACIÃ“N ---
        target_column = 'clasificacion_level_2'
        
        if target_column not in df.columns:
            st.warning(f"No se encontrÃ³ la columna '{target_column}' para la comparaciÃ³n de documentos.")
            return

        # Agrupar por documento y la nueva columna de taxonomÃ­a
        doc_type_counts = df.groupby(['documento_origen', target_column]).size().reset_index(name='count')
        
        # Crear el grÃ¡fico de barras apiladas usando la nueva columna para el color
        fig = px.bar(
            doc_type_counts,
            x='documento_origen',
            y='count',
            color=target_column, # <-- AquÃ­ estÃ¡ el cambio clave
            title='Tags por Documento y CategorÃ­a (Level 2)',
            color_discrete_map=self.color_scheme
        )
        # --- FIN DE LA MODIFICACIÃ“N ---
        
        fig.update_layout(
            xaxis_title="Documento",
            yaxis_title="NÃºmero de Tags",
            height=400,
            margin=dict(l=20, r=20, t=60, b=100),
            xaxis_tickangle=-45,
            legend_title_text='CategorÃ­a (Level 2)' # <-- Etiqueta mejorada
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_tag_frequency_chart(self, df: pd.DataFrame):
        """Render tag frequency analysis"""
        st.subheader("ðŸ”¢ Tag Frequency Analysis")
        
        # Count tag occurrences
        tag_counts = df['tag_capturado'].value_counts().head(20)
        
        # Create horizontal bar chart
        fig = go.Figure(go.Bar(
            x=tag_counts.values,
            y=tag_counts.index,
            orientation='h',
            marker_color='#1f77b4'
        ))
        
        fig.update_layout(
            xaxis_title="Occurrences",
            yaxis_title="Tag",
            height=600,
            margin=dict(l=150, r=20, t=40, b=40),
            yaxis=dict(autorange="reversed")
        )
        
        st.plotly_chart(fig, use_container_width=True)

    def render_data_table(self, results: List[Dict[str, Any]]):
        """
        [VERSIÃ“N FINAL]
        Renderiza una tabla de datos interactiva, completamente integrada con la nueva
        estructura de datos basada en taxonomÃ­a. Incluye:
        - Filtros por documento y por la nueva columna 'clasificacion_level_2'.
        - Columnas de visualizaciÃ³n relevantes para el anÃ¡lisis industrial.
        - BÃºsqueda de texto completo y paginaciÃ³n.
        - ProgramaciÃ³n defensiva para manejar datos incompletos o vacÃ­os.
        """
        st.subheader("ðŸ“‹ Tabla de Resultados Detallados")

        if not results:
            st.warning("No hay datos disponibles para mostrar en la tabla.")
            return

        try:
            df = pd.DataFrame(results)
        except Exception as e:
            st.error(f"No se pudieron cargar los resultados en la tabla. Error: {e}")
            st.write("Datos problemÃ¡ticos recibidos:")
            st.json(results[:5]) # Muestra los primeros 5 resultados para depuraciÃ³n
            return

        # --- LÃ“GICA DE CONFIGURACIÃ“N DE LA TABLA ---
        
        # Columna principal para el filtrado de tipos de tag
        filter_column = 'clasificacion_level_2'

        # Definir las columnas que queremos mostrar al usuario en el orden deseado
        display_columns = [
            'documento_origen',
            'area',
            'tag_capturado',
            'tag_formateado',
            'clasificacion_level_1',
            'clasificacion_level_2',
            'tag_code',
            'pagina_encontrada',
            'regex_captura', # Columna de debugging
            'contexto_linea'
        ]

        # ProgramaciÃ³n defensiva: nos aseguramos de que solo intentamos mostrar
        # las columnas que realmente existen en el DataFrame.
        valid_display_columns = [col for col in display_columns if col in df.columns]

        # --- LÃ“GICA DE RENDERIZADO DE FILTROS ---
        st.write("#### Filtros de BÃºsqueda")
        filter_cols = st.columns((2, 2, 1, 1)) # Asignar proporciones a las columnas

        with filter_cols[0]:
            # Filtro por Documento
            if 'documento_origen' in df.columns:
                documents = ['Todos'] + sorted(df['documento_origen'].unique().tolist())
                selected_doc = st.selectbox("Filtrar por Documento", documents, key="doc_filter")
            else:
                selected_doc = 'Todos'
                st.selectbox("Filtrar por Documento", ['N/A'], disabled=True, key="doc_filter")
        
        with filter_cols[1]:
            # Filtro por CategorÃ­a (Level 2)
            if filter_column in df.columns:
                types = ['Todas'] + sorted(df[filter_column].dropna().unique().tolist())
                selected_type = st.selectbox(f"Filtrar por CategorÃ­a ({filter_column})", types, key="type_filter")
            else:
                selected_type = 'Todas'
                st.selectbox(f"Filtrar por CategorÃ­a ({filter_column})", ['N/A'], disabled=True, key="type_filter")

        with filter_cols[2]:
            # Filtro por PÃ¡gina MÃ­nima
            min_page_val = int(df['pagina_encontrada'].min()) if 'pagina_encontrada' in df.columns and not df.empty else 0
            min_page = st.number_input("PÃ¡g. MÃ­n.", min_value=0, value=min_page_val, key="min_page_filter")
        
        with filter_cols[3]:
            # Filtro por PÃ¡gina MÃ¡xima
            max_page_val = int(df['pagina_encontrada'].max()) if 'pagina_encontrada' in df.columns and not df.empty else 1
            max_page = st.number_input("PÃ¡g. MÃ¡x.", min_value=min_page_val, value=max_page_val, key="max_page_filter")

        # --- LÃ“GICA DE APLICACIÃ“N DE FILTROS ---
        
        filtered_df = df.copy()

        if selected_doc != 'Todos' and 'documento_origen' in filtered_df.columns:
            filtered_df = filtered_df[filtered_df['documento_origen'] == selected_doc]
        
        if selected_type != 'Todas' and filter_column in filtered_df.columns:
            # Usar .dropna() para evitar errores si hay valores nulos en la columna de filtro
            filtered_df = filtered_df[filtered_df[filter_column].dropna() == selected_type]
        
        if 'pagina_encontrada' in filtered_df.columns:
            filtered_df = filtered_df[
                (filtered_df['pagina_encontrada'] >= min_page) & 
                (filtered_df['pagina_encontrada'] <= max_page)
            ]

        # --- LÃ“GICA DE BÃšSQUEDA DE TEXTO ---
        
        search_term = st.text_input("ðŸ” Buscar en resultados...", placeholder="Escriba para buscar en cualquier campo de la tabla...")
        
        if search_term:
            # Realizar una bÃºsqueda insensible a mayÃºsculas/minÃºsculas en todas las columnas visibles
            mask = filtered_df[valid_display_columns].astype(str).apply(
                lambda row: row.str.contains(search_term, case=False, na=False)
            ).any(axis=1)
            filtered_df = filtered_df[mask]

        # --- LÃ“GICA DE VISUALIZACIÃ“N DE LA TABLA Y PAGINACIÃ“N ---
        
        st.markdown(f"**{len(filtered_df)} resultados encontrados**")

        if not filtered_df.empty:
            # ConfiguraciÃ³n de paginaciÃ³n
            rows_per_page = st.slider("Resultados por pÃ¡gina", 10, 100, 25, key="rows_per_page_slider")
            
            total_pages = max(1, (len(filtered_df) - 1) // rows_per_page + 1)
            current_page = st.number_input("PÃ¡gina", min_value=1, max_value=total_pages, value=1, key="page_selector")
            
            start_idx = (current_page - 1) * rows_per_page
            end_idx = start_idx + rows_per_page
            
            # Mostrar la porciÃ³n del DataFrame correspondiente a la pÃ¡gina actual
            st.dataframe(
                filtered_df[valid_display_columns].iloc[start_idx:end_idx],
                use_container_width=True,
                hide_index=True,
                height= (min(rows_per_page, len(filtered_df.iloc[start_idx:end_idx])) + 1) * 35 # Altura dinÃ¡mica
            )
        else:
            st.info("No hay resultados que coincidan con los filtros aplicados.")
        
        # --- LÃ“GICA DE EXPORTACIÃ“N ---

        if not filtered_df.empty:
            # Convertir a CSV para descarga
            csv_data = filtered_df.to_csv(index=False).encode('utf-8')
            
            st.download_button(
                label="ðŸ’¾ Descargar Resultados Filtrados (CSV)",
                data=csv_data,
                file_name=f"filtered_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
    def render_heatmap(self, results: List[Dict[str, Any]]):
        """
        Render heatmap visualization
        
        Args:
            results: List of extraction results
        """
        st.subheader("ðŸ”¥ Tag Density Heatmap")
        
        if not results:
            st.warning("No data for heatmap")
            return
        
        df = pd.DataFrame(results)
        
        # Create pivot table for heatmap
        # Group by document and page ranges
        df['page_range'] = pd.cut(df['pagina_encontrada'], bins=10)
        
        pivot_data = df.groupby(['documento_origen', 'page_range']).size().reset_index(name='count')
        pivot_table = pivot_data.pivot(index='documento_origen', columns='page_range', values='count').fillna(0)
        
        # Create heatmap
        fig = go.Figure(data=go.Heatmap(
            z=pivot_table.values,
            x=[str(col) for col in pivot_table.columns],
            y=pivot_table.index,
            colorscale='Blues',
            showscale=True,
            hoverongaps=False
        ))
        
        fig.update_layout(
            xaxis_title="Page Range",
            yaxis_title="Document",
            height=400 + len(pivot_table.index) * 30,  # Dynamic height
            margin=dict(l=200, r=20, t=40, b=100),
            xaxis_tickangle=-45
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Additional insights
        st.subheader("ðŸ” Heatmap Insights")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Highest density areas
            max_density = pivot_table.max().max()
            max_location = pivot_table.stack().idxmax()
            
            st.info(f"**Highest Tag Density:** {int(max_density)} tags")
            st.info(f"**Location:** Document '{max_location[0]}' in page range {max_location[1]}")
        
        with col2:
            # Coverage statistics
            coverage = (pivot_table > 0).sum().sum() / pivot_table.size * 100
            
            st.info(f"**Coverage:** {coverage:.1f}% of document-page combinations have tags")
            st.info(f"**Average Density:** {pivot_table.mean().mean():.1f} tags per section")
    
    def render_advanced_analytics(self, results: List[Dict[str, Any]]):
        """Render advanced analytics dashboard"""
        st.subheader("ðŸŽ¯ Advanced Analytics")
        
        if not results:
            st.warning("No data for analysis")
            return
        
        df = pd.DataFrame(results)
        
        # Create tabs for different analyses
        tab1, tab2, tab3 = st.tabs(["Pattern Analysis", "Correlation Matrix", "Anomaly Detection"])
        
        with tab1:
            self.render_pattern_analysis(df)
        
        with tab2:
            self.render_correlation_matrix(df)
        
        with tab3:
            self.render_anomaly_detection(df)
    
    def render_pattern_analysis(self, df: pd.DataFrame):
        """Analyze patterns in extracted tags"""
        st.write("### Pattern Distribution")
        
        # Analyze tag patterns
        pattern_stats = {}
        
        for equipment_type in df['tipo_elemento'].unique():
            type_df = df[df['tipo_elemento'] == equipment_type]
            
            if len(type_df) > 0:
                # Extract pattern characteristics
                tags = type_df['tag_capturado'].tolist()
                
                # Length distribution
                lengths = [len(tag) for tag in tags]
                
                # Numeric vs alphabetic ratio
                numeric_chars = sum(sum(c.isdigit() for c in tag) for tag in tags)
                alpha_chars = sum(sum(c.isalpha() for c in tag) for tag in tags)
                
                pattern_stats[equipment_type] = {
                    'count': len(tags),
                    'avg_length': np.mean(lengths),
                    'min_length': min(lengths),
                    'max_length': max(lengths),
                    'numeric_ratio': numeric_chars / (numeric_chars + alpha_chars) if (numeric_chars + alpha_chars) > 0 else 0
                }
        
        # Display pattern statistics
        stats_df = pd.DataFrame(pattern_stats).T
        
        # Create visualization
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('Average Tag Length', 'Tag Count', 'Length Range', 'Numeric Ratio')
        )
        
        # Average length
        fig.add_trace(
            go.Bar(x=stats_df.index, y=stats_df['avg_length'], name='Avg Length'),
            row=1, col=1
        )
        
        # Count
        fig.add_trace(
            go.Bar(x=stats_df.index, y=stats_df['count'], name='Count'),
            row=1, col=2
        )
        
        # Length range
        fig.add_trace(
            go.Bar(x=stats_df.index, y=stats_df['max_length'] - stats_df['min_length'], name='Length Range'),
            row=2, col=1
        )
        
        # Numeric ratio
        fig.add_trace(
            go.Bar(x=stats_df.index, y=stats_df['numeric_ratio'], name='Numeric Ratio'),
            row=2, col=2
        )
        
        fig.update_layout(height=600, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)
    
    def render_correlation_matrix(self, df: pd.DataFrame):
        """Render correlation matrix between different metrics"""
        st.write("### Feature Correlation Matrix")
        
        # Prepare data for correlation
        correlation_data = df.groupby('documento_origen').agg({
            'tag_capturado': 'count',
            'pagina_encontrada': ['mean', 'std', 'min', 'max'],
            'tipo_elemento': lambda x: x.nunique()
        }).reset_index()
        
        # Flatten column names
        correlation_data.columns = ['document', 'tag_count', 'avg_page', 'std_page', 'min_page', 'max_page', 'type_diversity']
        
        # Calculate correlation matrix
        corr_matrix = correlation_data.select_dtypes(include=[np.number]).corr()
        
        # Create heatmap
        fig = go.Figure(data=go.Heatmap(
            z=corr_matrix.values,
            x=corr_matrix.columns,
            y=corr_matrix.columns,
            colorscale='RdBu',
            zmid=0,
            text=np.round(corr_matrix.values, 2),
            texttemplate='%{text}',
            showscale=True
        ))
        
        fig.update_layout(
            height=500,
            margin=dict(l=100, r=20, t=40, b=100)
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    def render_anomaly_detection(self, df: pd.DataFrame):
        """Detect and highlight anomalies in the data"""
        st.write("### Anomaly Detection")
        
        anomalies = []
        
        # Check for unusual tag lengths
        avg_length = df['tag_capturado'].str.len().mean()
        std_length = df['tag_capturado'].str.len().std()
        
        length_anomalies = df[
            (df['tag_capturado'].str.len() < avg_length - 2*std_length) |
            (df['tag_capturado'].str.len() > avg_length + 2*std_length)
        ]
        
        if len(length_anomalies) > 0:
            anomalies.append({
                'type': 'Tag Length',
                'count': len(length_anomalies),
                'description': f'Tags with unusual length (outside 2 std dev)',
                'examples': length_anomalies['tag_capturado'].head(5).tolist()
            })
        
        # Check for rare equipment types
        type_counts = df['tipo_elemento'].value_counts()
        rare_types = type_counts[type_counts < type_counts.mean() * 0.1].index.tolist()
        
        if rare_types:
            anomalies.append({
                'type': 'Rare Equipment Types',
                'count': len(rare_types),
                'description': 'Equipment types with very few occurrences',
                'examples': rare_types
            })
        
        # Check for page outliers
        page_q1 = df['pagina_encontrada'].quantile(0.25)
        page_q3 = df['pagina_encontrada'].quantile(0.75)
        page_iqr = page_q3 - page_q1
        
        page_outliers = df[
            (df['pagina_encontrada'] < page_q1 - 1.5*page_iqr) |
            (df['pagina_encontrada'] > page_q3 + 1.5*page_iqr)
        ]
        
        if len(page_outliers) > 0:
            anomalies.append({
                'type': 'Page Number Outliers',
                'count': len(page_outliers),
                'description': 'Tags found on unusual page numbers',
                'examples': page_outliers['pagina_encontrada'].unique()[:5].tolist()
            })
        
        # Display anomalies
        if anomalies:
            for anomaly in anomalies:
                with st.expander(f"âš ï¸ {anomaly['type']} ({anomaly['count']} found)"):
                    st.write(f"**Description:** {anomaly['description']}")
                    st.write(f"**Examples:** {anomaly['examples']}")
        else:
            st.success("âœ… No significant anomalies detected")
    
    def generate_summary_report(self, results: List[Dict[str, Any]]) -> str:
        """
        Generate a text summary report
        
        Args:
            results: List of extraction results
            
        Returns:
            Summary report as string
        """
        if not results:
            return "No results to summarize"
        
        df = pd.DataFrame(results)
        
        report = []
        report.append("# PDF Tag Extraction Summary Report")
        report.append("=" * 50)
        report.append("")
        
        # Overall statistics
        report.append("## Overall Statistics")
        report.append(f"- Total tags extracted: {len(df)}")
        report.append(f"- Unique tags: {df['tag_capturado'].nunique()}")
        report.append(f"- Documents processed: {df['documento_origen'].nunique()}")
        report.append(f"- Page range: {df['pagina_encontrada'].min()} - {df['pagina_encontrada'].max()}")
        report.append("")
        
        # Tag distribution
        report.append("## Tag Distribution by Type")
        type_counts = df['tipo_elemento'].value_counts()
        for equipment_type, count in type_counts.items():
            percentage = (count / len(df)) * 100
            report.append(f"- {equipment_type}: {count} ({percentage:.1f}%)")
        report.append("")
        
        # Document summary
        report.append("## Document Summary")
        doc_counts = df.groupby('documento_origen')['tag_capturado'].count().sort_values(ascending=False)
        for doc, count in doc_counts.items():
            report.append(f"- {doc}: {count} tags")
        report.append("")
        
        # Top tags
        report.append("## Most Frequent Tags (Top 10)")
        top_tags = df['tag_capturado'].value_counts().head(10)
        for tag, count in top_tags.items():
            report.append(f"- {tag}: {count} occurrences")
        
        return "\n".join(report)